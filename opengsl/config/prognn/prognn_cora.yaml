model:
  type: gcn
  n_layers: 2
  n_linear: 1 # layers of linear per gcn layer
  act: F.relu # [relu, elu, gelu, leakyrelu]
  n_hidden: 16
  dropout: 0.5
  input_dropout: 0
  norm:
    flag: false
    norm_type: BatchNorm1d # [LayerNorm, BatchNorm1d]
  input_layer: false
  output_layer: false
  spmm_type: 0 # specilized for sparse mltiply [0,1], expected to remove in future versions

training:
  lr: 5e-4
  n_epochs: 1000
  weight_decay: 5e-4
  patience_iter: 10000
  lr_adj: 1e-2
  inner_steps: 2
  outer_steps: 1
  patience: ~
  criterion: either

gsl:
  symmetric: false
  lambda_: 0.001
  alpha: 5e-4
  beta: 1.5
  gamma: 1

dataset:
  feat_norm: false # feats not normalized for prognn
  sparse: true

# analysis
analysis:
  flag: false
  project: gsl
  save_graph: false
  save_graph_path: results/graph