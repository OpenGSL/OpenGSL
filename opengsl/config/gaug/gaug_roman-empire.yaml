model:
  type: gcn
  n_hidden: 32
  n_layers: 2
  n_linear: 1 # layers of linear per gcn layer
  act: F.relu # [relu, elu, gelu, leakyrelu, identity]
  dropout: 0.5
  input_dropout: 0
  norm: ~
  input_layer: false
  output_layer: false
  spmm_type: 0 # specilized for sparse mltiply [0,1], expected to remove in future versions
  K: 6
  alpha: 0.5

gsl:
  n_hidden: 128
  n_embed: 32
  n_layers: 2
  n_linear: 1 # layers of linear per gcn layer
  act: 'lambda x: x' # [relu, elu, gelu, leakyrelu, identity]
  dropout: 0
  input_dropout: 0
  norm: ~
  input_layer: false
  output_layer: false
  spmm_type: 0 # specilized for sparse mltiply [0,1], expected to remove in future versions
  gae: true
  alpha: 0.1
  temperature: 0.3

dataset:
  feat_norm: false
  cora_split: false # for cora,citeseer and pubmed
  sparse: true
  without_structure: ~

training:
  lr: 1e-1
  n_epochs: 500
  weight_decay: 5e-5
  warmup: 10
  patience: 100
  pretrain_ep: 5
  pretrain_nc: 100
  beta: 2.5
  criterion: ~

# analysis
analysis:
  flag: false
  project: gsl
  save_graph: false
  save_graph_path: results/graph