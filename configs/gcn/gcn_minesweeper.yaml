model:
  n_layers: 5
  n_linear: 2 # layers of linear per gcn layer
  act: gelu # [relu, elu, gelu, leakyrelu]
  n_hidden: 512
  dropout: 0.2
  input_dropout: 0.2
  norm:
    flag: true
    norm_type: LayerNorm # [LayerNorm, BatchNorm1d]
  input_layer: true
  output_layer: true
  spmm_type: 0 # specilized for sparse mltiply [0,1], expected to remove in future versions

dataset:
  re_split: false # for cora,citeseer and pubmed

training:
  data_cpu: false # whether data should be placed in cpu instead of gpu to save space
  lr: 3e-5
  n_epochs: 1000
  weight_decay: 0

analysis:
  flag: true
  project: gsl